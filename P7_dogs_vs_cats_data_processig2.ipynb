{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载训练集和测试集\n",
    "\n",
    "import math\n",
    "import os\n",
    "#import hashlib\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dogs vs cats Data\n"
     ]
    }
   ],
   "source": [
    "# 下载猫狗训练数据集并解压  \n",
    "data_path = './data'  \n",
    "model_path ='./models'\n",
    "if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "url = 'https://storage.googleapis.com/kaggle-competitions-data/kaggle/5441/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1521432384&Signature=EfOTgFyuNXghYaxo4e6rCkSgJUrZPvPCokVmGLotFVH%2BVywjjEId4CEZS6E%2BlHUbO2xluKaOofYYX%2FJwaSi3BFE9TD%2BjSey1BmtinJnh070m2hSi9bgW%2BV%2F6uxedBw%2FFs%2B5yD7qHMrU3eFY31hxs37osloNdw4LzhqlxLPnbdICag5p8EawoFnS%2FYtQ5Iw6BlB%2BTe4IwnSTIqK6BZQFhCfax1j8KVjAr4galJH3QfaO3ygrVb7v60olInInBpeL2prgxKfTO2rvuZABN1xOezZNGHMrw0tL7cEMy1dA%2FHgX%2Bor9P8LxbtIpMvLF1FJgucFJlwbsISiYYPXOS%2BafkxQ%3D%3D'\n",
    "extract_path = os.path.join(data_path, 'train')\n",
    "save_path = os.path.join(data_path, 'train.zip')\n",
    "database_name ='dogs vs cats'\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "def _unzip(save_path, _, database_name, data_path):\n",
    "    print('Extracting {}...'.format(database_name))\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(data_path)\n",
    "        \n",
    "def download_extract(data_path, url, database_name, save_path, extract_path):\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    if os.path.exists(extract_path):\n",
    "        print('Found {} Data'.format(database_name))\n",
    "        return\n",
    "        \n",
    "    if not os.path.exists(save_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading {}'.format(database_name)) as pbar:\n",
    "            urlretrieve(url,save_path,pbar.hook)\n",
    "            \n",
    "    os.makedirs(extract_path)\n",
    "\n",
    "    try:\n",
    "        print('Extracting {}...'.format(database_name))\n",
    "        with zipfile.ZipFile(save_path) as zf:\n",
    "            zf.extractall(data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    # Remove compressed data\n",
    "    os.remove(save_path)\n",
    "    print(\"Finished downloading and extraction\")\n",
    "    \n",
    "download_extract(data_path, url, database_name, save_path, extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images already moved\n"
     ]
    }
   ],
   "source": [
    "#将猫狗分别放进dog，cat两个文件夹\n",
    "#将训练集分成训练集和验证集\n",
    "\n",
    "train_dir = './data/train/'\n",
    "validate_dir = './data/validate/'\n",
    "\n",
    "image_files = os.listdir(train_dir)\n",
    "image_files = [image_file for image_file in image_files if os.path.isfile(train_dir+image_file)]\n",
    "classes = ['dog','cat']\n",
    "train_dirs = [train_dir+each+'/' for each in classes]\n",
    "validate_dirs = [validate_dir+each+'/' for each in classes]\n",
    "\n",
    "flag = True\n",
    "for path in train_dirs:\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        flag = False\n",
    "for path in validate_dirs:\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        flag = False\n",
    "if not flag:\n",
    "    print(\"Moving images to correct folders.\")\n",
    "    for image_file in image_files:\n",
    "        if classes[0] in image_file:\n",
    "            shutil.move(train_dir+image_file, train_dirs[0]+os.path.basename(image_file))\n",
    "        else:\n",
    "            shutil.move(train_dir+image_file, train_dirs[1]+os.path.basename(image_file))\n",
    "\n",
    "    for ii, image_file in enumerate(os.listdir(train_dirs[0]), 1):\n",
    "        if ii >12000:\n",
    "            shutil.move(train_dirs[0]+image_file, validate_dirs[0]+os.path.basename(image_file))\n",
    "    for ii, image_file in enumerate(os.listdir(train_dirs[1]), 1):\n",
    "        if ii >12000:\n",
    "            shutil.move(train_dirs[1]+image_file, validate_dirs[1]+os.path.basename(image_file))\n",
    "    print(\"Moving finished.\")\n",
    "else:\n",
    "    print(\"Images already moved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data/\n",
    "    train/\n",
    "        dog/ ### 12000 pictures\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/ ### 12000 pictures\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dog/ ### 500 pictures\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cat/ ### 500 pictures\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_train_and_validation_generators(img_width, img_height, train_dir, validate_dir, batch_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # automagically retrieve images and their classes for train and validation sets\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "            validate_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def get_augmented_train_and_validation_generators(img_width, img_height, train_dir, validate_dir, batch_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    datagen_augmented =ImageDataGenerator(\n",
    "        rescale=1./255,        # normalize pixel values to [0,1]\n",
    "        shear_range=0.2,       # randomly applies shearing transformation\n",
    "        zoom_range=0.2,        # randomly applies shearing transformation\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    # automagically retrieve images and their classes for train and validation sets\n",
    "    train_generator = datagen_augmented.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "            validate_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def get_bottleneck_train_and_validation_generators(img_width, img_height, train_dir, validate_dir, batch_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # automagically retrieve images and their classes for train and validation sets\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "            validate_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps,\n",
    "                      train_generator, validation_generator,\n",
    "                      train_optimizer1,train_optimizer2,\n",
    "                      last_layers_count,dense_layer_num,model_name, \n",
    "                      img_width,img_height):\n",
    "    x = Input((img_width, img_height,3))\n",
    "    base_model=MODEL(input_tensor=x,weights='imagenet', include_top=False)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(dense_layer_num, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(top_model) \n",
    "    print(len(base_model.layers))\n",
    "    print(len(top_model.layers))\n",
    "           \n",
    "    #train only the top layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=train_optimizer1, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        shuffle = True)\n",
    "    print('finish fine-tuning step1')\n",
    "    \n",
    "    # choose a few more layers to train\n",
    "    layer_index = len(base_model.layers)-last_layers_count\n",
    "    for layer in base_model.layers[:layer_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[layer_index:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=train_optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        shuffle =True)\n",
    "\n",
    "    print(\"finish fine-tuning step2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "19\n",
      "4\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 82s 110ms/step - loss: 8.0487 - acc: 0.5002 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "finish fine-tuning step1\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 82s 110ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "finish fine-tuning step2\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning VGG16\n",
    "\n",
    "img_width=224\n",
    "img_height=224\n",
    "nb_epoch = 1\n",
    "batch_size =32\n",
    "nb_train_samples = 24000\n",
    "nb_validation_samples = 1000\n",
    "MODEL=VGG16\n",
    "train_optimizer1 = 'rmsprop'\n",
    "train_optimizer2 = SGD(lr=0.0001, momentum=0.9)\n",
    "last_layers_count =3\n",
    "dense_layer_num =512\n",
    "model_name='VGG16'\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "validation_steps = nb_validation_samples//batch_size\n",
    "\n",
    "train_generator, validation_generator = get_train_and_validation_generators(img_width, img_height, \n",
    "                                                                            train_dir, validate_dir, batch_size)\n",
    "fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps, \n",
    "                  train_generator, validation_generator,\n",
    "                 train_optimizer1,train_optimizer2, \n",
    "                  last_layers_count,dense_layer_num,model_name,img_width,img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "311\n",
      "4\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 94s 126ms/step - loss: 1.5590 - acc: 0.8987 - val_loss: 0.4287 - val_acc: 0.9720\n",
      "finish fine-tuning step1\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 93s 124ms/step - loss: 0.9899 - acc: 0.9365 - val_loss: 0.5932 - val_acc: 0.9620\n",
      "finish fine-tuning step2\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning InceptionV3\n",
    "\n",
    "img_width=299\n",
    "img_height=299\n",
    "nb_epoch = 1\n",
    "batch_size =32\n",
    "nb_train_samples = 24000\n",
    "nb_validation_samples = 1000\n",
    "MODEL=InceptionV3\n",
    "train_optimizer1 = 'rmsprop'\n",
    "train_optimizer2 = SGD(lr=0.0001, momentum=0.9)\n",
    "last_layers_count =3\n",
    "dense_layer_num =512\n",
    "model_name='InceptionV3'\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "validation_steps = nb_validation_samples//batch_size\n",
    "\n",
    "train_generator, validation_generator = get_train_and_validation_generators(img_width, img_height, \n",
    "                                                                            train_dir, validate_dir, batch_size)\n",
    "fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps, \n",
    "                  train_generator, validation_generator,\n",
    "                 train_optimizer1,train_optimizer2, \n",
    "                  last_layers_count,dense_layer_num,model_name,img_width,img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "132\n",
      "4\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 114s 152ms/step - loss: 0.7593 - acc: 0.9497 - val_loss: 0.2073 - val_acc: 0.9870\n",
      "finish fine-tuning step1\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 112s 149ms/step - loss: 0.4443 - acc: 0.9712 - val_loss: 0.2741 - val_acc: 0.9830\n",
      "finish fine-tuning step2\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning Xception\n",
    "\n",
    "img_width=299\n",
    "img_height=299\n",
    "nb_epoch = 1\n",
    "batch_size =32\n",
    "nb_train_samples = 24000\n",
    "nb_validation_samples = 1000\n",
    "MODEL=Xception\n",
    "train_optimizer1 = 'rmsprop'\n",
    "train_optimizer2 = SGD(lr=0.0001, momentum=0.9)\n",
    "last_layers_count =3\n",
    "dense_layer_num =512\n",
    "model_name='Xception'\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "validation_steps = nb_validation_samples//batch_size\n",
    "\n",
    "train_generator, validation_generator = get_train_and_validation_generators(img_width, img_height, \n",
    "                                                                            train_dir, validate_dir, batch_size)\n",
    "fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps, \n",
    "                  train_generator, validation_generator,\n",
    "                 train_optimizer1,train_optimizer2, \n",
    "                  last_layers_count,dense_layer_num,model_name,img_width,img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 2s 0us/step\n",
      "780\n",
      "4\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 157s 210ms/step - loss: 7.9635 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "finish fine-tuning step1\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 155s 206ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "finish fine-tuning step2\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning InceptionResNetV2\n",
    "\n",
    "img_width=299\n",
    "img_height=299\n",
    "nb_epoch = 1\n",
    "batch_size =32\n",
    "nb_train_samples = 24000\n",
    "nb_validation_samples = 1000\n",
    "MODEL=InceptionResNetV2\n",
    "train_optimizer1 = 'rmsprop'\n",
    "train_optimizer2 = SGD(lr=0.0001, momentum=0.9)\n",
    "last_layers_count =3\n",
    "dense_layer_num =512\n",
    "model_name='InceptionResNetV2'\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "validation_steps = nb_validation_samples//batch_size\n",
    "\n",
    "train_generator, validation_generator = get_train_and_validation_generators(img_width, img_height, \n",
    "                                                                            train_dir, validate_dir, batch_size)\n",
    "fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps, \n",
    "                  train_generator, validation_generator,\n",
    "                 train_optimizer1,train_optimizer2, \n",
    "                  last_layers_count,dense_layer_num,model_name,img_width,img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "175\n",
      "4\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 112s 149ms/step - loss: 0.2004 - acc: 0.9501 - val_loss: 0.0656 - val_acc: 0.9770\n",
      "finish fine-tuning step1\n",
      "Epoch 1/1\n",
      "750/750 [==============================] - 105s 140ms/step - loss: 0.0841 - acc: 0.9747 - val_loss: 0.0403 - val_acc: 0.9830\n",
      "finish fine-tuning step2\n"
     ]
    }
   ],
   "source": [
    "#fine-tuning ResNet50\n",
    "\n",
    "img_width=299\n",
    "img_height=299\n",
    "nb_epoch = 1\n",
    "batch_size =32\n",
    "nb_train_samples = 24000\n",
    "nb_validation_samples = 1000\n",
    "MODEL=ResNet50\n",
    "train_optimizer1 = 'rmsprop'\n",
    "train_optimizer2 = SGD(lr=0.0001, momentum=0.9)\n",
    "last_layers_count =3\n",
    "dense_layer_num =512\n",
    "model_name='ResNet50'\n",
    "steps_per_epoch = nb_train_samples//batch_size\n",
    "validation_steps = nb_validation_samples//batch_size\n",
    "\n",
    "train_generator, validation_generator = get_train_and_validation_generators(img_width, img_height, \n",
    "                                                                            train_dir, validate_dir, batch_size)\n",
    "fine_tuning_model(MODEL, nb_epoch, steps_per_epoch, validation_steps, \n",
    "                  train_generator, validation_generator,\n",
    "                 train_optimizer1,train_optimizer2, \n",
    "                  last_layers_count,dense_layer_num,model_name,img_width,img_height)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
